{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"neural network for prediction with some input and one output\"\"\"\n",
    "\n",
    "#function for mult two vectors\n",
    "def mult_vec(a,b):\n",
    "    assert len(a) == len(b)\n",
    "    output = 0 \n",
    "    for i in range(len(a)):\n",
    "        output += a[i] * b[i]\n",
    "    return output\n",
    "\n",
    "#function for rearization neural network\n",
    "def neural_net(input_s, weights):\n",
    "    return mult_vec(input_s, weights)\n",
    "\n",
    "print(neural_net([.1,.2,0], [5,3,1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Code with use NumPy\"\"\"\n",
    "weights = np.array([0.1, 0.2, 0]) # weights for our neural network\n",
    "input_s = np.array([5,3,1])\n",
    "\n",
    "def neural_net(input_s, weights):\n",
    "    return input_s.dot(weights)\n",
    "\n",
    "print(neural_net(input_s, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2135 0.145  0.5065]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Neural network with hidden layer for calculate prediction with NumPy\"\"\"\n",
    "ih_wgt = np.array([[.1, .2, -.1],\n",
    "                  [-.1, .1, .9],\n",
    "                  [.1, .4, .1]]).T\n",
    "hp_wgt = np.array([\n",
    "    [.3, 1.1, -.3],\n",
    "    [.1, .2, .0],\n",
    "    [.0, 1.3, .1]\n",
    "]).T\n",
    "weights = [ih_wgt, hp_wgt]\n",
    "\n",
    "def neural_net(input_s, weigts):\n",
    "    hid = input_s.dot(weights[0]) #first layer(hidden)\n",
    "    return hid.dot(weights[1]) # second layer(out)\n",
    "\n",
    "input_s = np.array([8.5, .65, 1.2])\n",
    "\n",
    "print(neural_net(input_s, weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Secrets of NumPy\"\"\"\n",
    "a = np.array([1,2,3,4]) #This is vector\n",
    "b = np.array([5,6,7,8]) # This is too vector, but vector others numbers\n",
    "c = np.array([\n",
    "    [.1, .2, .3],\n",
    "    [.5, -.4, .3],\n",
    "    [-.1, -.2, -.15]\n",
    "]) # But this is Matrix(Vector of vectors)\n",
    "d = np.zeros((3,4))\n",
    "e = np.random.rand(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Befor learning.\n",
      "Error : 0.022499999999999975. Predict : 0.8500000000000001. Should be Predict : 1\n",
      "\n",
      "After one iteration learning\n",
      "Error : 0.004455562500000012. Predict : 1.06675. Should be Predict : 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Function for calculate error\"\"\"\n",
    "MSE = lambda y_pred, y: (y_pred - y) ** 2\n",
    "\n",
    "\"\"\"Gradient descent\"\"\"\n",
    "\n",
    "weight = .1\n",
    "alpha = .01\n",
    "\n",
    "def neural_net(input_s, weight):\n",
    "    return input_s * weight\n",
    "#Dataset for prediction\n",
    "goal_predict = 1\n",
    "data = 8.5\n",
    "\n",
    "pred = neural_net(data, weight)\n",
    "error = MSE(pred, goal_predict)\n",
    "print(\"Befor learning.\\nError : {0}. Predict : {1}. Should be Predict : {2}\".format(error, pred, goal_predict))\n",
    "\n",
    "#Learning Gradient descent - w_new = w_prew - lr*func(w_prew)\n",
    "weight -= alpha*2*data*(pred-goal_predict)\n",
    "pred = neural_net(data, weight)\n",
    "error = MSE(pred, goal_predict)\n",
    "\n",
    "print(\"\\nAfter one iteration learning\\nError : {0}. Predict : {1}. Should be Predict : {2}\".format(error, pred, goal_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : ____________0_____________\n",
      "Error : 0.7569.\n",
      "weight : 0.12262.\n",
      "Predict : 0.13\n",
      "iteration : ____________1_____________\n",
      "Error : 0.706598272836.\n",
      "weight : 0.144475444.\n",
      "Predict : 0.15940600000000002\n",
      "iteration : ____________2_____________\n",
      "Error : 0.6596394757231052.\n",
      "weight : 0.16559217399280002.\n",
      "Predict : 0.18781807720000002\n",
      "iteration : ____________3_____________\n",
      "Error : 0.6158014456868682.\n",
      "weight : 0.1859951585118434.\n",
      "Predict : 0.21526982619064003\n",
      "iteration : ____________4_____________\n",
      "Error : 0.5748767841620465.\n",
      "weight : 0.2057085221541431.\n",
      "Predict : 0.2417937060653964\n",
      "iteration : ____________5_____________\n",
      "Error : 0.5366718757859903.\n",
      "weight : 0.22475557410533306.\n",
      "Predict : 0.267421078800386\n",
      "iteration : ____________6_____________\n",
      "Error : 0.5010059724006302.\n",
      "weight : 0.2431588357005728.\n",
      "Predict : 0.292182246336933\n",
      "iteration : ____________7_____________\n",
      "Error : 0.46771033792945693.\n",
      "weight : 0.26094006705389344.\n",
      "Predict : 0.3161064864107447\n",
      "iteration : ____________8_____________\n",
      "Error : 0.43662745008388976.\n",
      "weight : 0.27812029278747186.\n",
      "Predict : 0.33922208717006147\n",
      "iteration : ____________9_____________\n",
      "Error : 0.4076102551222927.\n",
      "weight : 0.2947198268912553.\n",
      "Predict : 0.3615563806237134\n",
      "iteration : ____________10_____________\n",
      "Error : 0.3805214721358876.\n",
      "weight : 0.3107582967423309.\n",
      "Predict : 0.38313577495863194\n",
      "iteration : ____________11_____________\n",
      "Error : 0.35523294357012847.\n",
      "weight : 0.3262546663124401.\n",
      "Predict : 0.4039857857650302\n",
      "iteration : ____________12_____________\n",
      "Error : 0.3316250289088401.\n",
      "weight : 0.3412272585910796.\n",
      "Predict : 0.42413106620617214\n",
      "iteration : ____________13_____________\n",
      "Error : 0.30958603865262907.\n",
      "weight : 0.3556937772507011.\n",
      "Predict : 0.4435954361684035\n",
      "iteration : ____________14_____________\n",
      "Error : 0.2890117059137098.\n",
      "weight : 0.3696713275796274.\n",
      "Predict : 0.46240191042591144\n",
      "iteration : ____________15_____________\n",
      "Error : 0.26980469312724703.\n",
      "weight : 0.383176436707436.\n",
      "Predict : 0.4805727258535156\n",
      "iteration : ____________16_____________\n",
      "Error : 0.25187413154546145.\n",
      "weight : 0.39622507314672467.\n",
      "Predict : 0.4981293677196668\n",
      "iteration : ____________17_____________\n",
      "Error : 0.23513519133583097.\n",
      "weight : 0.4088326656743654.\n",
      "Predict : 0.5150925950907421\n",
      "iteration : ____________18_____________\n",
      "Error : 0.21950868024951856.\n",
      "weight : 0.42101412157457185.\n",
      "Predict : 0.531482465376675\n",
      "iteration : ____________19_____________\n",
      "Error : 0.20492066896131533.\n",
      "weight : 0.4327838442653513.\n",
      "Predict : 0.5473183580469434\n",
      "iteration : ____________20_____________\n",
      "Error : 0.1913021413085786.\n",
      "weight : 0.4441557503291825.\n",
      "Predict : 0.5626189975449567\n",
      "iteration : ____________21_____________\n",
      "Error : 0.17858866777443522.\n",
      "weight : 0.4551432859680561.\n",
      "Predict : 0.5774024754279372\n",
      "iteration : ____________22_____________\n",
      "Error : 0.16672010067049567.\n",
      "weight : 0.4657594429023358.\n",
      "Predict : 0.5916862717584729\n",
      "iteration : ____________23_____________\n",
      "Error : 0.15564028957698015.\n",
      "weight : 0.47601677373223683.\n",
      "Predict : 0.6054872757730365\n",
      "iteration : ____________24_____________\n",
      "Error : 0.14529681569400058.\n",
      "weight : 0.4859274067800872.\n",
      "Predict : 0.6188218058519079\n",
      "iteration : ____________25_____________\n",
      "Error : 0.13564074384720762.\n",
      "weight : 0.4955030604309203.\n",
      "Predict : 0.6317056288141134\n",
      "iteration : ____________26_____________\n",
      "Error : 0.12662639097453715.\n",
      "weight : 0.5047550569883552.\n",
      "Predict : 0.6441539785601964\n",
      "iteration : ____________27_____________\n",
      "Error : 0.11821110999876339.\n",
      "weight : 0.5136943360621488.\n",
      "Predict : 0.6561815740848618\n",
      "iteration : ____________28_____________\n",
      "Error : 0.11035508806335398.\n",
      "weight : 0.5223314675032481.\n",
      "Predict : 0.6678026368807934\n",
      "iteration : ____________29_____________\n",
      "Error : 0.10302115817707837.\n",
      "weight : 0.5306766639016384.\n",
      "Predict : 0.6790309077542226\n",
      "iteration : ____________30_____________\n",
      "Error : 0.09617462337625568.\n",
      "weight : 0.538739792661763.\n",
      "Predict : 0.6898796630721299\n",
      "iteration : ____________31_____________\n",
      "Error : 0.08978309257275074.\n",
      "weight : 0.5465303876697953.\n",
      "Predict : 0.7003617304602919\n",
      "iteration : ____________32_____________\n",
      "Error : 0.08381632731111167.\n",
      "weight : 0.5540576605665563.\n",
      "Predict : 0.710489503970734\n",
      "iteration : ____________33_____________\n",
      "Error : 0.07824609870985383.\n",
      "weight : 0.5613305116394066.\n",
      "Predict : 0.7202749587365231\n",
      "iteration : ____________34_____________\n",
      "Error : 0.07304605391007782.\n",
      "weight : 0.5683575403459946.\n",
      "Predict : 0.7297296651312286\n",
      "iteration : ____________35_____________\n",
      "Error : 0.06819159139958562.\n",
      "weight : 0.5751470554823.\n",
      "Predict : 0.738864802449793\n",
      "iteration : ____________36_____________\n",
      "Error : 0.06365974462265214.\n",
      "weight : 0.5817070850069983.\n",
      "Predict : 0.7476911721269901\n",
      "iteration : ____________37_____________\n",
      "Error : 0.059429073324807576.\n",
      "weight : 0.5880453855337617.\n",
      "Predict : 0.7562192105090978\n",
      "iteration : ____________38_____________\n",
      "Error : 0.05547956211857976.\n",
      "weight : 0.5941694515027206.\n",
      "Predict : 0.7644590011938903\n",
      "iteration : ____________39_____________\n",
      "Error : 0.051792525790310524.\n",
      "weight : 0.6000865240419286.\n",
      "Predict : 0.7724202869535368\n",
      "iteration : ____________40_____________\n",
      "Error : 0.04835052090004942.\n",
      "weight : 0.6058035995293114.\n",
      "Predict : 0.7801124812545073\n",
      "iteration : ____________41_____________\n",
      "Error : 0.045137263256303184.\n",
      "weight : 0.6113274378652207.\n",
      "Predict : 0.7875446793881048\n",
      "iteration : ____________42_____________\n",
      "Error : 0.04213755087521159.\n",
      "weight : 0.6166645704653763.\n",
      "Predict : 0.7947256692247869\n",
      "iteration : ____________43_____________\n",
      "Error : 0.03933719205966913.\n",
      "weight : 0.6218213079836465.\n",
      "Predict : 0.8016639416049892\n",
      "iteration : ____________44_____________\n",
      "Error : 0.03672293825813217.\n",
      "weight : 0.6268037477737993.\n",
      "Predict : 0.8083677003787405\n",
      "iteration : ____________45_____________\n",
      "Error : 0.034282421385466035.\n",
      "weight : 0.6316177810990449.\n",
      "Predict : 0.8148448721059391\n",
      "iteration : ____________46_____________\n",
      "Error : 0.032004095309296154.\n",
      "weight : 0.6362691000978972.\n",
      "Predict : 0.8211031154287584\n",
      "iteration : ____________47_____________\n",
      "Error : 0.029877181225032863.\n",
      "weight : 0.6407632045145882.\n",
      "Predict : 0.8271498301272664\n",
      "iteration : ____________48_____________\n",
      "Error : 0.027891616661139387.\n",
      "weight : 0.6451054082019951.\n",
      "Predict : 0.8329921658689647\n",
      "iteration : ____________49_____________\n",
      "Error : 0.02603800787338474.\n",
      "weight : 0.6493008454047677.\n",
      "Predict : 0.8386370306625937\n",
      "iteration : ____________50_____________\n",
      "Error : 0.02430758540285878.\n",
      "weight : 0.6533544768300866.\n",
      "Predict : 0.844091099026198\n",
      "iteration : ____________51_____________\n",
      "Error : 0.022692162587493157.\n",
      "weight : 0.6572710955132297.\n",
      "Predict : 0.8493608198791126\n",
      "iteration : ____________52_____________\n",
      "Error : 0.02118409683080505.\n",
      "weight : 0.6610553324848826.\n",
      "Predict : 0.8544524241671987\n",
      "iteration : ____________53_____________\n",
      "Error : 0.019776253444626017.\n",
      "weight : 0.6647116622468936.\n",
      "Predict : 0.8593719322303474\n",
      "iteration : ____________54_____________\n",
      "Error : 0.018461971894754552.\n",
      "weight : 0.6682444080629486.\n",
      "Predict : 0.8641251609209617\n",
      "iteration : ____________55_____________\n",
      "Error : 0.017235034289840585.\n",
      "weight : 0.6716577470704209.\n",
      "Predict : 0.8687177304818332\n",
      "iteration : ____________56_____________\n",
      "Error : 0.016089635964421454.\n",
      "weight : 0.6749557152194406.\n",
      "Predict : 0.8731550711915472\n",
      "iteration : ____________57_____________\n",
      "Error : 0.01502035801693777.\n",
      "weight : 0.6781422120450236.\n",
      "Predict : 0.8774424297852729\n",
      "iteration : ____________58_____________\n",
      "Error : 0.014022141672805657.\n",
      "weight : 0.6812210052779017.\n",
      "Predict : 0.8815848756585306\n",
      "iteration : ____________59_____________\n",
      "Error : 0.01309026435125667.\n",
      "weight : 0.6841957352995087.\n",
      "Predict : 0.8855873068612723\n",
      "iteration : ____________60_____________\n",
      "Error : 0.012220317322717158.\n",
      "weight : 0.6870699194463853.\n",
      "Predict : 0.8894544558893613\n",
      "iteration : ____________61_____________\n",
      "Error : 0.01140818485102364.\n",
      "weight : 0.6898469561690974.\n",
      "Predict : 0.8931908952803009\n",
      "iteration : ____________62_____________\n",
      "Error : 0.010650024721795668.\n",
      "weight : 0.6925301290505819.\n",
      "Predict : 0.8968010430198267\n",
      "iteration : ____________63_____________\n",
      "Error : 0.009942250064845472.\n",
      "weight : 0.6951226106886722.\n",
      "Predict : 0.9002891677657564\n",
      "iteration : ____________64_____________\n",
      "Error : 0.009281512384625979.\n",
      "weight : 0.697627466447395.\n",
      "Predict : 0.9036593938952739\n",
      "iteration : ____________65_____________\n",
      "Error : 0.008664685718433977.\n",
      "weight : 0.7000476580814731.\n",
      "Predict : 0.9069157063816136\n",
      "iteration : ____________66_____________\n",
      "Error : 0.008088851847420002.\n",
      "weight : 0.7023860472383193.\n",
      "Predict : 0.9100619555059151\n",
      "iteration : ____________67_____________\n",
      "Error : 0.007551286490438965.\n",
      "weight : 0.7046453988416641.\n",
      "Predict : 0.9131018614098152\n",
      "iteration : ____________68_____________\n",
      "Error : 0.007049446415423442.\n",
      "weight : 0.7068283843608159.\n",
      "Predict : 0.9160390184941634\n",
      "iteration : ____________69_____________\n",
      "Error : 0.006580957407303659.\n",
      "weight : 0.7089375849694203.\n",
      "Predict : 0.9188768996690606\n",
      "iteration : ____________70_____________\n",
      "Error : 0.00614360303555032.\n",
      "weight : 0.7109754945974539.\n",
      "Predict : 0.9216188604602464\n",
      "iteration : ____________71_____________\n",
      "Error : 0.0057353141681990485.\n",
      "weight : 0.7129445228800599.\n",
      "Predict : 0.9242681429766901\n",
      "iteration : ____________72_____________\n",
      "Error : 0.005354159182747112.\n",
      "weight : 0.7148469980067139.\n",
      "Predict : 0.926827879744078\n",
      "iteration : ____________73_____________\n",
      "Error : 0.004998334827610149.\n",
      "weight : 0.716685169474087.\n",
      "Predict : 0.9293010974087281\n",
      "iteration : ____________74_____________\n",
      "Error : 0.0046661576909041505.\n",
      "weight : 0.7184612107458629.\n",
      "Predict : 0.9316907203163132\n",
      "iteration : ____________75_____________\n",
      "Error : 0.0043560562361914315.\n",
      "weight : 0.7201772218226528.\n",
      "Predict : 0.9339995739696217\n",
      "iteration : ____________76_____________\n",
      "Error : 0.004066563367511355.\n",
      "weight : 0.721835231725047.\n",
      "Predict : 0.9362303883694486\n",
      "iteration : ____________77_____________\n",
      "Error : 0.0037963094885211713.\n",
      "weight : 0.7234372008927404.\n",
      "Predict : 0.9383858012425612\n",
      "iteration : ____________78_____________\n",
      "Error : 0.003544016022909206.\n",
      "weight : 0.7249850235025658.\n",
      "Predict : 0.9404683611605626\n",
      "iteration : ____________79_____________\n",
      "Error : 0.0033084893654257612.\n",
      "weight : 0.726480529708179.\n",
      "Predict : 0.9424805305533356\n",
      "iteration : ____________80_____________\n",
      "Error : 0.0030886152349136236.\n",
      "weight : 0.7279254878040425.\n",
      "Predict : 0.9444246886206328\n",
      "iteration : ____________81_____________\n",
      "Error : 0.0028833534026224414.\n",
      "weight : 0.7293216063162659.\n",
      "Predict : 0.9463031341452554\n",
      "iteration : ____________82_____________\n",
      "Error : 0.002691732770866466.\n",
      "weight : 0.7306705360227761.\n",
      "Predict : 0.9481180882111456\n",
      "iteration : ____________83_____________\n",
      "Error : 0.00251284677874264.\n",
      "weight : 0.7319738719052062.\n",
      "Predict : 0.9498716968296089\n",
      "iteration : ____________84_____________\n",
      "Error : 0.0023458491131735427.\n",
      "weight : 0.7332331550348102.\n",
      "Predict : 0.9515660334767682\n",
      "iteration : ____________85_____________\n",
      "Error : 0.0021899497049838704.\n",
      "weight : 0.7344498743946336.\n",
      "Predict : 0.9532031015452533\n",
      "iteration : ____________86_____________\n",
      "Error : 0.0020444109910679274.\n",
      "weight : 0.735625468640095.\n",
      "Predict : 0.9547848367130237\n",
      "iteration : ____________87_____________\n",
      "Error : 0.0019085444249643698.\n",
      "weight : 0.7367613278000599.\n",
      "Predict : 0.9563131092321235\n",
      "iteration : ____________88_____________\n",
      "Error : 0.0017817072193296276.\n",
      "weight : 0.7378587949204178.\n",
      "Predict : 0.9577897261400778\n",
      "iteration : ____________89_____________\n",
      "Error : 0.0016632993048985995.\n",
      "weight : 0.7389191676521077.\n",
      "Predict : 0.9592164333965432\n",
      "iteration : ____________90_____________\n",
      "Error : 0.0015527604915453353.\n",
      "weight : 0.7399436997854665.\n",
      "Predict : 0.9605949179477401\n",
      "iteration : ____________91_____________\n",
      "Error : 0.0014495678180128347.\n",
      "weight : 0.7409336027327177.\n",
      "Predict : 0.9619268097211064\n",
      "iteration : ____________92_____________\n",
      "Error : 0.0013532330777731806.\n",
      "weight : 0.7418900469603519.\n",
      "Predict : 0.963213683552533\n",
      "iteration : ____________93_____________\n",
      "Error : 0.0012633005093130756.\n",
      "weight : 0.742814163373092.\n",
      "Predict : 0.9644570610484575\n",
      "iteration : ____________94_____________\n",
      "Error : 0.001179344639917368.\n",
      "weight : 0.7437070446510815.\n",
      "Predict : 0.9656584123850197\n",
      "iteration : ____________95_____________\n",
      "Error : 0.0011009682727493872.\n",
      "weight : 0.7445697465418749.\n",
      "Predict : 0.966819158046406\n",
      "iteration : ____________96_____________\n",
      "Error : 0.0010278006077050477.\n",
      "weight : 0.7454032891087595.\n",
      "Predict : 0.9679406705044374\n",
      "iteration : ____________97_____________\n",
      "Error : 0.0009594954871504566.\n",
      "weight : 0.7462086579368834.\n",
      "Predict : 0.9690242758413874\n",
      "iteration : ____________98_____________\n",
      "Error : 0.000895729758243428.\n",
      "weight : 0.7469868052986167.\n",
      "Predict : 0.9700712553179485\n",
      "iteration : ____________99_____________\n",
      "Error : 0.0008362017440911809.\n",
      "weight : 0.7477386512795234.\n",
      "Predict : 0.9710828468882018\n",
      "iteration : ____________100_____________\n",
      "Error : 0.0007806298165111386.\n",
      "weight : 0.7484650848662755.\n",
      "Predict : 0.9720602466633805\n",
      "iteration : ____________101_____________\n",
      "Error : 0.0007287510636425673.\n",
      "weight : 0.7491669649977953.\n",
      "Predict : 0.9730046103261581\n",
      "iteration : ____________102_____________\n",
      "Error : 0.0006803200461054803.\n",
      "weight : 0.7498451215808698.\n",
      "Predict : 0.973917054497134\n",
      "iteration : ____________103_____________\n",
      "Error : 0.000635107635822225.\n",
      "weight : 0.7505003564714364.\n",
      "Predict : 0.9747986580551308\n",
      "iteration : ____________104_____________\n",
      "Error : 0.0005928999320081077.\n",
      "weight : 0.7511334444227019.\n",
      "Predict : 0.9756504634128674\n",
      "iteration : ____________105_____________\n",
      "Error : 0.0005534972492026815.\n",
      "weight : 0.7517451340012146.\n",
      "Predict : 0.9764734777495125\n",
      "iteration : ____________106_____________\n",
      "Error : 0.0005167131725539635.\n",
      "weight : 0.7523361484719735.\n",
      "Predict : 0.9772686742015789\n",
      "iteration : ____________107_____________\n",
      "Error : 0.00048237367588616564.\n",
      "weight : 0.7529071866536208.\n",
      "Predict : 0.9780369930135656\n",
      "iteration : ____________108_____________\n",
      "Error : 0.000450316298378544.\n",
      "weight : 0.7534589237447283.\n",
      "Predict : 0.978779342649707\n",
      "iteration : ____________109_____________\n",
      "Error : 0.00042038937596007743.\n",
      "weight : 0.7539920121221565.\n",
      "Predict : 0.9794966008681468\n",
      "iteration : ____________110_____________\n",
      "Error : 0.0003924513237838475.\n",
      "weight : 0.7545070821124276.\n",
      "Predict : 0.9801896157588035\n",
      "iteration : ____________111_____________\n",
      "Error : 0.00036636996638640386.\n",
      "weight : 0.7550047427370276.\n",
      "Predict : 0.9808592067461559\n",
      "iteration : ____________112_____________\n",
      "Error : 0.0003420219123630804.\n",
      "weight : 0.7554855824325161.\n",
      "Predict : 0.9815061655581359\n",
      "iteration : ____________113_____________\n",
      "Error : 0.00031929197060089504.\n",
      "weight : 0.755950169746297.\n",
      "Predict : 0.9821312571622709\n",
      "iteration : ____________114_____________\n",
      "Error : 0.0002980726053071676.\n",
      "weight : 0.7563990540088722.\n",
      "Predict : 0.9827352206701861\n",
      "iteration : ____________115_____________\n",
      "Error : 0.00027826342725560844.\n",
      "weight : 0.7568327659833723.\n",
      "Predict : 0.9833187702115339\n",
      "iteration : ____________116_____________\n",
      "Error : 0.00025977071884296187.\n",
      "weight : 0.7572518184931344.\n",
      "Predict : 0.9838825957783841\n",
      "iteration : ____________117_____________\n",
      "Error : 0.00024250699070921077.\n",
      "weight : 0.7576567070280664.\n",
      "Predict : 0.9844273640410748\n",
      "iteration : ____________118_____________\n",
      "Error : 0.0002263905678237344.\n",
      "weight : 0.7580479103305178.\n",
      "Predict : 0.9849537191364864\n",
      "iteration : ____________119_____________\n",
      "Error : 0.0002113452030791566.\n",
      "weight : 0.7584258909613463.\n",
      "Predict : 0.9854622834296731\n",
      "iteration : ____________120_____________\n",
      "Error : 0.00019729971656480975.\n",
      "weight : 0.7587910958468528.\n",
      "Predict : 0.9859536582497502\n",
      "iteration : ____________121_____________\n",
      "Error : 0.00018418765881322217.\n",
      "weight : 0.7591439568072291.\n",
      "Predict : 0.9864284246009086\n",
      "iteration : ____________122_____________\n",
      "Error : 0.00017194699642638313.\n",
      "weight : 0.7594848910671448.\n",
      "Predict : 0.9868871438493979\n",
      "iteration : ____________123_____________\n",
      "Error : 0.00016051981859455794.\n",
      "weight : 0.7598143017490753.\n",
      "Predict : 0.9873303583872882\n",
      "iteration : ____________124_____________\n",
      "Error : 0.00014985206311912.\n",
      "weight : 0.7601325783499565.\n",
      "Predict : 0.9877585922737979\n",
      "iteration : ____________125_____________\n",
      "Error : 0.00013989326064325956.\n",
      "weight : 0.760440097201728.\n",
      "Predict : 0.9881723518549435\n",
      "iteration : ____________126_____________\n",
      "Error : 0.00013059629588046254.\n",
      "weight : 0.7607372219163095.\n",
      "Predict : 0.9885721263622465\n",
      "iteration : ____________127_____________\n",
      "Error : 0.00012191718471121086.\n",
      "weight : 0.7610243038155383.\n",
      "Predict : 0.9889583884912024\n",
      "iteration : ____________128_____________\n",
      "Error : 0.00011381486609323335.\n",
      "weight : 0.7613016823465731.\n",
      "Predict : 0.9893315949601998\n",
      "iteration : ____________129_____________\n",
      "Error : 0.00010625100780095076.\n",
      "weight : 0.761569685483259.\n",
      "Predict : 0.9896921870505451\n",
      "iteration : ____________130_____________\n",
      "Error : 9.918982507495705e-05.\n",
      "weight : 0.7618286301139249.\n",
      "Predict : 0.9900405911282367\n",
      "iteration : ____________131_____________\n",
      "Error : 9.259791132364721e-05.\n",
      "weight : 0.7620788224160742.\n",
      "Predict : 0.9903772191481024\n",
      "iteration : ____________132_____________\n",
      "Error : 8.644408007598306e-05.\n",
      "weight : 0.7623205582184108.\n",
      "Predict : 0.9907024691408964\n",
      "iteration : ____________133_____________\n",
      "Error : 8.069921743768992e-05.\n",
      "weight : 0.7625541233506286.\n",
      "Predict : 0.9910167256839341\n",
      "iteration : ____________134_____________\n",
      "Error : 7.533614435287033e-05.\n",
      "weight : 0.7627797939813773.\n",
      "Predict : 0.9913203603558172\n",
      "iteration : ____________135_____________\n",
      "Error : 7.032948801937122e-05.\n",
      "weight : 0.7629978369448067.\n",
      "Predict : 0.9916137321757905\n",
      "iteration : ____________136_____________\n",
      "Error : 6.565556184955494e-05.\n",
      "weight : 0.7632085100560723.\n",
      "Predict : 0.9918971880282488\n",
      "iteration : ____________137_____________\n",
      "Error : 6.1292253408605e-05.\n",
      "weight : 0.763412062416177.\n",
      "Predict : 0.9921710630728939\n",
      "iteration : ____________138_____________\n",
      "Error : 5.7218919800167835e-05.\n",
      "weight : 0.7636087347065103.\n",
      "Predict : 0.9924356811410301\n",
      "iteration : ____________139_____________\n",
      "Error : 5.3416290004411095e-05.\n",
      "weight : 0.7637987594734302.\n",
      "Predict : 0.9926913551184634\n",
      "iteration : ____________140_____________\n",
      "Error : 4.986637370646528e-05.\n",
      "weight : 0.7639823614032283.\n",
      "Predict : 0.9929383873154594\n",
      "iteration : ____________141_____________\n",
      "Error : 4.655237618388527e-05.\n",
      "weight : 0.7641597575877992.\n",
      "Predict : 0.9931770698241968\n",
      "iteration : ____________142_____________\n",
      "Error : 4.345861885050209e-05.\n",
      "weight : 0.7643311577813315.\n",
      "Predict : 0.993407684864139\n",
      "iteration : ____________143_____________\n",
      "Error : 4.057046508072854e-05.\n",
      "weight : 0.7644967646483225.\n",
      "Predict : 0.993630505115731\n",
      "iteration : ____________144_____________\n",
      "Error : 3.7874250963399e-05.\n",
      "weight : 0.7646567740032092.\n",
      "Predict : 0.9938457940428193\n",
      "iteration : ____________145_____________\n",
      "Error : 3.53572206575441e-05.\n",
      "weight : 0.7648113750419008.\n",
      "Predict : 0.9940538062041719\n",
      "iteration : ____________146_____________\n",
      "Error : 3.3007466044260696e-05.\n",
      "weight : 0.7649607505654845.\n",
      "Predict : 0.994254787554471\n",
      "iteration : ____________147_____________\n",
      "Error : 3.0813870389176475e-05.\n",
      "weight : 0.7651050771963711.\n",
      "Predict : 0.9944489757351299\n",
      "iteration : ____________148_____________\n",
      "Error : 2.876605574895632e-05.\n",
      "weight : 0.7652445255871337.\n",
      "Predict : 0.9946366003552825\n",
      "iteration : ____________149_____________\n",
      "Error : 2.6854333873056593e-05.\n",
      "weight : 0.7653792606222887.\n",
      "Predict : 0.9948178832632739\n",
      "iteration : ____________150_____________\n",
      "Error : 2.5069660368427764e-05.\n",
      "weight : 0.7655094416132553.\n",
      "Predict : 0.9949930388089753\n",
      "iteration : ____________151_____________\n",
      "Error : 2.3403591910313403e-05.\n",
      "weight : 0.7656352224867272.\n",
      "Predict : 0.9951622740972319\n",
      "iteration : ____________152_____________\n",
      "Error : 2.1848246296718885e-05.\n",
      "weight : 0.7657567519666758.\n",
      "Predict : 0.9953257892327454\n",
      "iteration : ____________153_____________\n",
      "Error : 2.039626515755986e-05.\n",
      "weight : 0.7658741737502022.\n",
      "Predict : 0.9954837775566786\n",
      "iteration : ____________154_____________\n",
      "Error : 1.9040779142075067e-05.\n",
      "weight : 0.7659876266774454.\n",
      "Predict : 0.9956364258752629\n",
      "iteration : ____________155_____________\n",
      "Error : 1.777537541979448e-05.\n",
      "weight : 0.7660972448957477.\n",
      "Predict : 0.995783914680679\n",
      "iteration : ____________156_____________\n",
      "Error : 1.659406734131062e-05.\n",
      "weight : 0.7662031580182714.\n",
      "Predict : 0.995926418364472\n",
      "iteration : ____________157_____________\n",
      "Error : 1.5491266115331348e-05.\n",
      "weight : 0.7663054912772539.\n",
      "Predict : 0.9960641054237529\n",
      "iteration : ____________158_____________\n",
      "Error : 1.4461754367995092e-05.\n",
      "weight : 0.7664043656720827.\n",
      "Predict : 0.9961971386604301\n",
      "iteration : ____________159_____________\n",
      "Error : 1.350066145937929e-05.\n",
      "weight : 0.7664998981123663.\n",
      "Predict : 0.9963256753737075\n",
      "iteration : ____________160_____________\n",
      "Error : 1.2603440440402817e-05.\n",
      "weight : 0.7665922015561684.\n",
      "Predict : 0.9964498675460762\n",
      "iteration : ____________161_____________\n",
      "Error : 1.1765846541128041e-05.\n",
      "weight : 0.7666813851435699.\n",
      "Predict : 0.9965698620230189\n",
      "iteration : ____________162_____________\n",
      "Error : 1.0983917088669787e-05.\n",
      "weight : 0.7667675543257172.\n",
      "Predict : 0.9966858006866409\n",
      "iteration : ____________163_____________\n",
      "Error : 1.0253952759715105e-05.\n",
      "weight : 0.7668508109895079.\n",
      "Predict : 0.9967978206234324\n",
      "iteration : ____________164_____________\n",
      "Error : 9.572500078949065e-06.\n",
      "weight : 0.7669312535780626.\n",
      "Predict : 0.9969060542863604\n",
      "iteration : ____________165_____________\n",
      "Error : 8.936335080602512e-06.\n",
      "weight : 0.767008977207124.\n",
      "Predict : 0.9970106296514814\n",
      "iteration : ____________166_____________\n",
      "Error : 8.34244805580319e-06.\n",
      "weight : 0.7670840737775232.\n",
      "Predict : 0.9971116703692613\n",
      "iteration : ____________167_____________\n",
      "Error : 7.788029313587977e-06.\n",
      "weight : 0.7671566320838429.\n",
      "Predict : 0.9972092959107802\n",
      "iteration : ____________168_____________\n",
      "Error : 7.270455888198838e-06.\n",
      "weight : 0.767226737919409.\n",
      "Predict : 0.9973036217089958\n",
      "iteration : ____________169_____________\n",
      "Error : 6.78727912978167e-06.\n",
      "weight : 0.767294474177733.\n",
      "Predict : 0.9973947592952317\n"
     ]
    }
   ],
   "source": [
    "MSE = lambda y_pred, y_goal: (y_pred - y_goal) ** 2\n",
    "\n",
    "input_s = 1.3\n",
    "goal_predict = 1.0\n",
    "weight = .1\n",
    "lr = 0.01\n",
    "\n",
    "def neural_net(input_s, weight):\n",
    "    return input_s * weight\n",
    "\n",
    "for i in range(170):\n",
    "    print(\"iteration : ____________{0}_____________\".format(i))\n",
    "    predict = neural_net(input_s, weight)\n",
    "    error = MSE(predict, goal_predict)\n",
    "    loss = 2 * input_s * (predict - goal_predict)\n",
    "    weight = weight - lr * loss\n",
    "    print(\"Error : {0}.\\nweight : {1}.\\nPredict : {2}\".format(error, weight, predict)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______Iteration : 0_____\n",
      "Error : 0.01959999999999997\n",
      "______Iteration : 0_____\n",
      "Error : 0.00920870544400002\n",
      "______Iteration : 0_____\n",
      "Error : 1.272130955257488\n",
      "______Iteration : 0_____\n",
      "Error : 0.988002819757008\n",
      "______Iteration : 0_____\n",
      "Error : 0.5852657185327654\n",
      "______Iteration : 1_____\n",
      "Error : 0.800462745700978\n",
      "______Iteration : 1_____\n",
      "Error : 0.015029630408529983\n",
      "______Iteration : 1_____\n",
      "Error : 1.2068179445880673\n",
      "______Iteration : 1_____\n",
      "Error : 0.9699015627098198\n",
      "______Iteration : 1_____\n",
      "Error : 0.5661225975974965\n",
      "______Iteration : 2_____\n",
      "Error : 0.7767760031304282\n",
      "______Iteration : 2_____\n",
      "Error : 0.014141688505273354\n",
      "______Iteration : 2_____\n",
      "Error : 1.180476778119032\n",
      "______Iteration : 2_____\n",
      "Error : 0.9518836123786807\n",
      "______Iteration : 2_____\n",
      "Error : 0.5475984716687005\n",
      "______Iteration : 3_____\n",
      "Error : 0.753759619066155\n",
      "______Iteration : 3_____\n",
      "Error : 0.013292208452959479\n",
      "______Iteration : 3_____\n",
      "Error : 1.154789590685136\n",
      "______Iteration : 3_____\n",
      "Error : 0.9342815445749251\n",
      "______Iteration : 3_____\n",
      "Error : 0.5296318137354721\n",
      "______Iteration : 4_____\n",
      "Error : 0.7314030227340477\n",
      "______Iteration : 4_____\n",
      "Error : 0.012480261580631837\n",
      "______Iteration : 4_____\n",
      "Error : 1.1297391061502746\n",
      "______Iteration : 4_____\n",
      "Error : 0.9170850155348643\n",
      "______Iteration : 4_____\n",
      "Error : 0.5122066359964151\n",
      "______Iteration : 5_____\n",
      "Error : 0.7096876466921915\n",
      "______Iteration : 5_____\n",
      "Error : 0.011704618707193132\n",
      "______Iteration : 5_____\n",
      "Error : 1.1053087385816196\n",
      "______Iteration : 5_____\n",
      "Error : 0.900283949170957\n",
      "______Iteration : 5_____\n",
      "Error : 0.49530739999422674\n",
      "______Iteration : 6_____\n",
      "Error : 0.6885954410478421\n",
      "______Iteration : 6_____\n",
      "Error : 0.010964087233456469\n",
      "______Iteration : 6_____\n",
      "Error : 1.0814823465884214\n",
      "______Iteration : 6_____\n",
      "Error : 0.8838685319553584\n",
      "______Iteration : 6_____\n",
      "Error : 0.47891900384710795\n",
      "______Iteration : 7_____\n",
      "Error : 0.668108859151139\n",
      "______Iteration : 7_____\n",
      "Error : 0.010257510098017248\n",
      "______Iteration : 7_____\n",
      "Error : 1.0582442212285772\n",
      "______Iteration : 7_____\n",
      "Error : 0.8678292058901832\n",
      "______Iteration : 7_____\n",
      "Error : 0.46302677010127996\n",
      "______Iteration : 8_____\n",
      "Error : 0.6482108436339667\n",
      "______Iteration : 8_____\n",
      "Error : 0.009583764760459633\n",
      "______Iteration : 8_____\n",
      "Error : 1.0355790742479558\n",
      "______Iteration : 8_____\n",
      "Error : 0.8521566616687287\n",
      "______Iteration : 8_____\n",
      "Error : 0.4476164339199579\n",
      "______Iteration : 9_____\n",
      "Error : 0.628884812835125\n",
      "______Iteration : 9_____\n",
      "Error : 0.008941762213116116\n",
      "______Iteration : 9_____\n",
      "Error : 1.0134720266419708\n",
      "______Iteration : 9_____\n",
      "Error : 0.8368418320224467\n",
      "______Iteration : 9_____\n",
      "Error : 0.4326741315994915\n",
      "______Iteration : 10_____\n",
      "Error : 0.6101146476011247\n",
      "______Iteration : 10_____\n",
      "Error : 0.008330446020585275\n",
      "______Iteration : 10_____\n",
      "Error : 0.9919085975305157\n",
      "______Iteration : 10_____\n",
      "Error : 0.8218758852485788\n",
      "______Iteration : 10_____\n",
      "Error : 0.41818638940362046\n",
      "______Iteration : 11_____\n",
      "Error : 0.5918846784522411\n",
      "______Iteration : 11_____\n",
      "Error : 0.007748791386235426\n",
      "______Iteration : 11_____\n",
      "Error : 0.9708746933376532\n",
      "______Iteration : 11_____\n",
      "Error : 0.8072502189135069\n",
      "______Iteration : 11_____\n",
      "Error : 0.40414011270705574\n",
      "______Iteration : 12_____\n",
      "Error : 0.5741796731037204\n",
      "______Iteration : 12_____\n",
      "Error : 0.0071958042449426956\n",
      "______Iteration : 12_____\n",
      "Error : 0.9503565972676883\n",
      "______Iteration : 12_____\n",
      "Error : 0.7929564537270218\n",
      "______Iteration : 12_____\n",
      "Error : 0.3905225754398356\n",
      "______Iteration : 13_____\n",
      "Error : 0.5569848243323305\n",
      "______Iteration : 13_____\n",
      "Error : 0.006670520381333211\n",
      "______Iteration : 13_____\n",
      "Error : 0.9303409590694569\n",
      "______Iteration : 13_____\n",
      "Error : 0.7789864275828173\n",
      "______Iteration : 13_____\n",
      "Error : 0.377321409824147\n",
      "______Iteration : 14_____\n",
      "Error : 0.5402857381787165\n",
      "______Iteration : 14_____\n",
      "Error : 0.006172004572819204\n",
      "______Iteration : 14_____\n",
      "Error : 0.9108147850809243\n",
      "______Iteration : 14_____\n",
      "Error : 0.7653321897606801\n",
      "______Iteration : 14_____\n",
      "Error : 0.3645245963955179\n"
     ]
    }
   ],
   "source": [
    "#Learning neural net with some inputs with gradient descent\n",
    "MSE = lambda y_pred, y_goal: (y_pred - y_goal) ** 2\n",
    "\n",
    "def ele_mul(number, vectors):\n",
    "    return number * np.array(vectors)\n",
    "\n",
    "def neural_net(input_s, weights):\n",
    "    return np.array(input_s).dot(np.array(weights))\n",
    "#init weights and dataset\n",
    "weights = [0.1, 0.2, -.1]\n",
    "\n",
    "toes = [8.5, 9.5, 9.9, 9.0, 9.1]\n",
    "wlrec = [.65, .8, .8, 1., .3]\n",
    "nfans = [1.2, 1.3, .5, 1., .3]\n",
    "\n",
    "win_or_lose = [1, 1, 0, 1, 0]\n",
    "\n",
    "#For very fast calculate outputs\n",
    "\n",
    "input_s = list(map(list, zip(toes, wlrec, nfans)))\n",
    "predicts = [neural_net(i, weights) for i in input_s]\n",
    "error = [MSE(i[0], i[1]) for i in zip(predicts, win_or_lose)]\n",
    "\n",
    "for iteration in range(15):\n",
    "    for i in input_s:\n",
    "        predict = neural_net(i, weights)\n",
    "        error = MSE(predict, win_or_lose[input_s.index(i)])\n",
    "        delta = (predict - win_or_lose[input_s.index(i)]) * np.array(i)\n",
    "        weights = np.array(weights) - 0.01 * delta\n",
    "        print(\"______Iteration : {0}_____\\nError : {1}\".format(iteration, error));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Iteration : 0.\n",
      "Error : 0.48999999999999994\n",
      ". \n",
      "Weights : \n",
      "[ 0.5   0.48 -0.63]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 1.\n",
      "Error : 0.42250000000000004\n",
      ". \n",
      "Weights : \n",
      "[ 0.565  0.545 -0.565]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 2.\n",
      "Error : 1.0404\n",
      ". \n",
      "Weights : \n",
      "[ 0.565  0.647 -0.463]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 3.\n",
      "Error : 0.6658560000000001\n",
      ". \n",
      "Weights : \n",
      "[ 0.565   0.7286 -0.3814]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 4.\n",
      "Error : 0.42614784000000006\n",
      ". \n",
      "Weights : \n",
      "[ 0.565    0.79388 -0.31612]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 5.\n",
      "Error : 0.27273461760000006\n",
      ". \n",
      "Weights : \n",
      "[ 0.565     0.846104 -0.263896]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 6.\n",
      "Error : 0.06964109881599997\n",
      ". \n",
      "Weights : \n",
      "[ 0.565      0.846104  -0.2375064]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 7.\n",
      "Error : 0.05640929004095998\n",
      ". \n",
      "Weights : \n",
      "[ 0.565       0.846104   -0.21375576]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 8.\n",
      "Error : 0.1351678166310976\n",
      ". \n",
      "Weights : \n",
      "[ 0.565       0.88286918 -0.17699058]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 9.\n",
      "Error : 0.08650740264390251\n",
      ". \n",
      "Weights : \n",
      "[ 0.565       0.91228132 -0.14757844]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 10.\n",
      "Error : 0.17424075608133566\n",
      ". \n",
      "Weights : \n",
      "[ 0.52325784  0.91228132 -0.1893206 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 11.\n",
      "Error : 0.11151408389205482\n",
      ". \n",
      "Weights : \n",
      "[ 0.48986412  0.91228132 -0.22271432]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 12.\n",
      "Error : 0.09636865160161641\n",
      ". \n",
      "Weights : \n",
      "[ 0.48986412  0.94332462 -0.19167102]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 13.\n",
      "Error : 0.06167593702503454\n",
      ". \n",
      "Weights : \n",
      "[ 0.48986412  0.96815926 -0.16683638]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 14.\n",
      "Error : 0.08478986636965531\n",
      ". \n",
      "Weights : \n",
      "[ 0.46074542  0.93904056 -0.19595508]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 15.\n",
      "Error : 0.06600507230645587\n",
      ". \n",
      "Weights : \n",
      "[ 0.46074542  0.96473201 -0.17026363]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 16.\n",
      "Error : 0.028989703513716818\n",
      ". \n",
      "Weights : \n",
      "[ 0.46074542  0.96473201 -0.15323727]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 17.\n",
      "Error : 0.094561264602271\n",
      ". \n",
      "Weights : \n",
      "[ 0.4299946   0.96473201 -0.18398808]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 18.\n",
      "Error : 0.06051920934545342\n",
      ". \n",
      "Weights : \n",
      "[ 0.40539395  0.96473201 -0.20858873]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 19.\n",
      "Error : 0.03873229398109018\n",
      ". \n",
      "Weights : \n",
      "[ 0.38571343  0.96473201 -0.22826926]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 20.\n",
      "Error : 0.014927020297536694\n",
      ". \n",
      "Weights : \n",
      "[ 0.37349581  0.95251439 -0.24048687]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 21.\n",
      "Error : 0.017691377483530883\n",
      ". \n",
      "Weights : \n",
      "[ 0.36019492  0.95251439 -0.25378777]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 22.\n",
      "Error : 0.09076564714379567\n",
      ". \n",
      "Weights : \n",
      "[ 0.36019492  0.98264173 -0.22366043]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 23.\n",
      "Error : 0.014202970824972428\n",
      ". \n",
      "Weights : \n",
      "[ 0.3482773   0.97072411 -0.23557805]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 24.\n",
      "Error : 0.006959455704236494\n",
      ". \n",
      "Weights : \n",
      "[ 0.33993496  0.96238177 -0.24392039]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 25.\n",
      "Error : 0.009218798369548092\n",
      ". \n",
      "Weights : \n",
      "[ 0.3303335   0.96238177 -0.25352185]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 26.\n",
      "Error : 0.00590003095651078\n",
      ". \n",
      "Weights : \n",
      "[ 0.32265234  0.96238177 -0.26120301]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 27.\n",
      "Error : 0.08929413234499127\n",
      ". \n",
      "Weights : \n",
      "[ 0.32265234  0.9922639  -0.23132089]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 28.\n",
      "Error : 0.0571482447007944\n",
      ". \n",
      "Weights : \n",
      "[ 0.32265234  1.0161696  -0.20741519]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 29.\n",
      "Error : 0.03657487660850845\n",
      ". \n",
      "Weights : \n",
      "[ 0.32265234  1.03529415 -0.18829063]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 30.\n",
      "Error : 0.018053068923090967\n",
      ". \n",
      "Weights : \n",
      "[ 0.30921617  1.03529415 -0.2017268 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 31.\n",
      "Error : 0.011553964110778225\n",
      ". \n",
      "Weights : \n",
      "[ 0.29846723  1.03529415 -0.21247574]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 32.\n",
      "Error : 0.03139331285255233\n",
      ". \n",
      "Weights : \n",
      "[ 0.29846723  1.05301231 -0.19475758]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 33.\n",
      "Error : 0.037930514336058506\n",
      ". \n",
      "Weights : \n",
      "[ 0.29846723  1.05301231 -0.17528182]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 34.\n",
      "Error : 0.015174645222409971\n",
      ". \n",
      "Weights : \n",
      "[ 0.28614869  1.05301231 -0.18760036]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 35.\n",
      "Error : 0.03519389564815495\n",
      ". \n",
      "Weights : \n",
      "[ 0.28614869  1.05301231 -0.16884033]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 36.\n",
      "Error : 0.013761252289361255\n",
      ". \n",
      "Weights : \n",
      "[ 0.27441785  1.05301231 -0.18057116]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 37.\n",
      "Error : 0.032605944471049496\n",
      ". \n",
      "Weights : \n",
      "[ 0.27441785  1.05301231 -0.16251405]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 38.\n",
      "Error : 0.026410815021550092\n",
      ". \n",
      "Weights : \n",
      "[ 0.27441785  1.05301231 -0.14626264]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 39.\n",
      "Error : 0.021392760167455577\n",
      ". \n",
      "Weights : \n",
      "[ 0.27441785  1.05301231 -0.13163638]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 40.\n",
      "Error : 0.03833520790610768\n",
      ". \n",
      "Weights : \n",
      "[ 0.25483847  1.03343293 -0.15121576]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 41.\n",
      "Error : 0.01073766774423548\n",
      ". \n",
      "Weights : \n",
      "[ 0.2444762   1.03343293 -0.16157803]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 42.\n",
      "Error : 0.006872107356310705\n",
      ". \n",
      "Weights : \n",
      "[ 0.23618638  1.03343293 -0.16986785]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 43.\n",
      "Error : 0.018614484932517314\n",
      ". \n",
      "Weights : \n",
      "[ 0.23618638  1.04707643 -0.15622435]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 44.\n",
      "Error : 0.011913270356811102\n",
      ". \n",
      "Weights : \n",
      "[ 0.23618638  1.05799122 -0.14530956]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 45.\n",
      "Error : 0.007624493028359093\n",
      ". \n",
      "Weights : \n",
      "[ 0.23618638  1.06672305 -0.13657773]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 46.\n",
      "Error : 0.00992188474426347\n",
      ". \n",
      "Weights : \n",
      "[ 0.22622552  1.06672305 -0.14653859]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 47.\n",
      "Error : 0.006350006236328622\n",
      ". \n",
      "Weights : \n",
      "[ 0.21825683  1.06672305 -0.15450729]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 48.\n",
      "Error : 0.02387250121701837\n",
      ". \n",
      "Weights : \n",
      "[ 0.21825683  1.06672305 -0.13905656]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 49.\n",
      "Error : 0.005232135847623569\n",
      ". \n",
      "Weights : \n",
      "[ 0.21825683  1.0739564  -0.13182321]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 50.\n",
      "Error : 0.02572495946771317\n",
      ". \n",
      "Weights : \n",
      "[ 0.20221782  1.0579174  -0.14786221]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 51.\n",
      "Error : 0.021863232747657193\n",
      ". \n",
      "Weights : \n",
      "[ 0.20221782  1.0579174  -0.13307599]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 52.\n",
      "Error : 0.0047805935327641805\n",
      ". \n",
      "Weights : \n",
      "[ 0.19530364  1.0579174  -0.13999017]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 53.\n",
      "Error : 0.0030595798609690758\n",
      ". \n",
      "Weights : \n",
      "[ 0.18977229  1.0579174  -0.14552152]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 54.\n",
      "Error : 0.010438336158514954\n",
      ". \n",
      "Weights : \n",
      "[ 0.17955548  1.04770058 -0.15573834]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 55.\n",
      "Error : 0.024254429273574105\n",
      ". \n",
      "Weights : \n",
      "[ 0.17955548  1.04770058 -0.1401645 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 56.\n",
      "Error : 0.0015516488073417014\n",
      ". \n",
      "Weights : \n",
      "[ 0.17561638  1.04770058 -0.1441036 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 57.\n",
      "Error : 0.0009930552366986885\n",
      ". \n",
      "Weights : \n",
      "[ 0.1724651   1.04770058 -0.14725488]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 58.\n",
      "Error : 0.009911057567491012\n",
      ". \n",
      "Weights : \n",
      "[ 0.1724651   1.05765601 -0.13729945]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 59.\n",
      "Error : 0.018851138456405663\n",
      ". \n",
      "Weights : \n",
      "[ 0.1724651   1.05765601 -0.1235695 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 60.\n",
      "Error : 0.015269422149688586\n",
      ". \n",
      "Weights : \n",
      "[ 0.1724651   1.05765601 -0.11121255]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 61.\n",
      "Error : 0.0037518746065713705\n",
      ". \n",
      "Weights : \n",
      "[ 0.16633985  1.05765601 -0.11733781]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 62.\n",
      "Error : 0.013768161129853488\n",
      ". \n",
      "Weights : \n",
      "[ 0.16633985  1.05765601 -0.10560403]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 63.\n",
      "Error : 0.011152210515181324\n",
      ". \n",
      "Weights : \n",
      "[ 0.16633985  1.05765601 -0.09504362]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 64.\n",
      "Error : 0.0013978335171133808\n",
      ". \n",
      "Weights : \n",
      "[ 0.16633985  1.06139477 -0.09130486]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 65.\n",
      "Error : 0.0008946134509525584\n",
      ". \n",
      "Weights : \n",
      "[ 0.16633985  1.06438578 -0.08831385]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 66.\n",
      "Error : 0.006088055397211891\n",
      ". \n",
      "Weights : \n",
      "[ 0.15853725  1.06438578 -0.09611645]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 67.\n",
      "Error : 0.016079907727654687\n",
      ". \n",
      "Weights : \n",
      "[ 0.14585659  1.05170512 -0.10879711]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 68.\n",
      "Error : 0.0013734049271076313\n",
      ". \n",
      "Weights : \n",
      "[ 0.14215064  1.05170512 -0.11250306]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 69.\n",
      "Error : 0.0036963887510963905\n",
      ". \n",
      "Weights : \n",
      "[ 0.14215064  1.05778492 -0.10642327]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 70.\n",
      "Error : 0.0012764453934117858\n",
      ". \n",
      "Weights : \n",
      "[ 0.1385779   1.05778492 -0.109996  ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 71.\n",
      "Error : 0.002725997356694898\n",
      ". \n",
      "Weights : \n",
      "[ 0.1385779   1.06300603 -0.10477489]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 72.\n",
      "Error : 0.0017446383082847254\n",
      ". \n",
      "Weights : \n",
      "[ 0.1385779   1.06718291 -0.10059801]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 73.\n",
      "Error : 0.010119959164446305\n",
      ". \n",
      "Weights : \n",
      "[ 0.1385779   1.06718291 -0.09053821]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 74.\n",
      "Error : 0.008197166923201505\n",
      ". \n",
      "Weights : \n",
      "[ 0.1385779   1.06718291 -0.08148439]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 75.\n",
      "Error : 0.0032596697379079637\n",
      ". \n",
      "Weights : \n",
      "[ 0.13286855  1.06718291 -0.08719374]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 76.\n",
      "Error : 0.000400433094281117\n",
      ". \n",
      "Weights : \n",
      "[ 0.13286855  1.069184   -0.08519266]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 77.\n",
      "Error : 0.002272991099876075\n",
      ". \n",
      "Weights : \n",
      "[ 0.12810096  1.069184   -0.08996025]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 78.\n",
      "Error : 0.0004316525301848997\n",
      ". \n",
      "Weights : \n",
      "[ 0.12810096  1.07126162 -0.08788262]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 79.\n",
      "Error : 0.0016175150378975377\n",
      ". \n",
      "Weights : \n",
      "[ 0.12407913  1.07126162 -0.09190445]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 80.\n",
      "Error : 0.00042612657712026686\n",
      ". \n",
      "Weights : \n",
      "[ 0.12407913  1.0733259  -0.08984017]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 81.\n",
      "Error : 0.0011723061765703542\n",
      ". \n",
      "Weights : \n",
      "[ 0.12065523  1.0733259  -0.09326407]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 82.\n",
      "Error : 0.0003975303255923882\n",
      ". \n",
      "Weights : \n",
      "[ 0.12065523  1.07531972 -0.09127025]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 83.\n",
      "Error : 0.00025441940837913057\n",
      ". \n",
      "Weights : \n",
      "[ 0.12065523  1.07691477 -0.0896752 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 84.\n",
      "Error : 0.0009597625598758254\n",
      ". \n",
      "Weights : \n",
      "[ 0.11755723  1.07691477 -0.0927732 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 85.\n",
      "Error : 0.0103426462191783\n",
      ". \n",
      "Weights : \n",
      "[ 0.10738735  1.06674489 -0.10294308]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 86.\n",
      "Error : 1.9751514452205758e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.10694292  1.06674489 -0.10338751]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 87.\n",
      "Error : 1.2640969249411606e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.10658738  1.06674489 -0.10374305]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 88.\n",
      "Error : 0.004842660193042895\n",
      ". \n",
      "Weights : \n",
      "[ 0.09962846  1.05978597 -0.11070197]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 89.\n",
      "Error : 0.0023729034945910187\n",
      ". \n",
      "Weights : \n",
      "[ 0.09475721  1.05491473 -0.11557322]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 90.\n",
      "Error : 0.0036794526963661255\n",
      ". \n",
      "Weights : \n",
      "[ 0.09475721  1.06098057 -0.10950737]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 91.\n",
      "Error : 0.002137251601344247\n",
      ". \n",
      "Weights : \n",
      "[ 0.09013417  1.05635753 -0.11413041]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 92.\n",
      "Error : 0.003337705387207492\n",
      ". \n",
      "Weights : \n",
      "[ 0.09013417  1.06213482 -0.10835312]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 93.\n",
      "Error : 0.0019286035080578576\n",
      ". \n",
      "Weights : \n",
      "[ 0.08574258  1.05774323 -0.11274471]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 94.\n",
      "Error : 0.0009450157189483571\n",
      ". \n",
      "Weights : \n",
      "[ 0.08266847  1.05466912 -0.11581882]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 95.\n",
      "Error : 0.003739285490231275\n",
      ". \n",
      "Weights : \n",
      "[ 0.08266847  1.06078409 -0.10970385]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 96.\n",
      "Error : 0.0023931427137480073\n",
      ". \n",
      "Weights : \n",
      "[ 0.08266847  1.06567607 -0.10481187]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 97.\n",
      "Error : 0.0004903302352739716\n",
      ". \n",
      "Weights : \n",
      "[ 0.08488281  1.06567607 -0.10259753]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 98.\n",
      "Error : 0.0013631946637163545\n",
      ". \n",
      "Weights : \n",
      "[ 0.08488281  1.06936821 -0.09890539]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 99.\n",
      "Error : 0.00978227573615528\n",
      ". \n",
      "Weights : \n",
      "[ 0.08488281  1.06936821 -0.08901485]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 100.\n",
      "Error : 0.007923643346285777\n",
      ". \n",
      "Weights : \n",
      "[ 0.08488281  1.06936821 -0.08011336]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 101.\n",
      "Error : 0.00641815111049148\n",
      ". \n",
      "Weights : \n",
      "[ 0.08488281  1.06936821 -0.07210203]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 102.\n",
      "Error : 0.005198702399498098\n",
      ". \n",
      "Weights : \n",
      "[ 0.08488281  1.06936821 -0.06489182]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 103.\n",
      "Error : 2.003806683705494e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.08488281  1.06892058 -0.06533946]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 104.\n",
      "Error : 0.0003819424976616254\n",
      ". \n",
      "Weights : \n",
      "[ 0.08292848  1.06892058 -0.0672938 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 105.\n",
      "Error : 0.007149591187136716\n",
      ". \n",
      "Weights : \n",
      "[ 0.07447295  1.06046505 -0.07574932]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 106.\n",
      "Error : 0.0035032996816970014\n",
      ". \n",
      "Weights : \n",
      "[ 0.06855408  1.05454618 -0.08166819]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 107.\n",
      "Error : 0.0007356034129268283\n",
      ". \n",
      "Weights : \n",
      "[ 0.06855408  1.05725838 -0.07895599]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 108.\n",
      "Error : 0.0004707861842731739\n",
      ". \n",
      "Weights : \n",
      "[ 0.06855408  1.05942814 -0.07678623]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 109.\n",
      "Error : 0.002621030269925786\n",
      ". \n",
      "Weights : \n",
      "[ 0.06343448  1.05430854 -0.08190583]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 110.\n",
      "Error : 0.0007616101920952822\n",
      ". \n",
      "Weights : \n",
      "[ 0.06343448  1.05706827 -0.0791461 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 111.\n",
      "Error : 0.0004874305229409767\n",
      ". \n",
      "Weights : \n",
      "[ 0.06343448  1.05927606 -0.07693832]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 112.\n",
      "Error : 0.00018235353032275707\n",
      ". \n",
      "Weights : \n",
      "[ 0.06478487  1.05927606 -0.07558794]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 113.\n",
      "Error : 0.00011670625940656446\n",
      ". \n",
      "Weights : \n",
      "[ 0.06586518  1.05927606 -0.07450763]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 114.\n",
      "Error : 0.005551386744100162\n",
      ". \n",
      "Weights : \n",
      "[ 0.06586518  1.05927606 -0.06705687]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 115.\n",
      "Error : 0.00449662326272113\n",
      ". \n",
      "Weights : \n",
      "[ 0.06586518  1.05927606 -0.06035118]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 116.\n",
      "Error : 3.0404149258581645e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.06531378  1.05927606 -0.06090258]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 117.\n",
      "Error : 0.004056066126732131\n",
      ". \n",
      "Weights : \n",
      "[ 0.05894505  1.05290733 -0.0672713 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 118.\n",
      "Error : 0.00020632373503640998\n",
      ". \n",
      "Weights : \n",
      "[ 0.05894505  1.05434373 -0.06583491]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 119.\n",
      "Error : 4.747012304402917e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.05963404  1.05434373 -0.06514592]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 120.\n",
      "Error : 0.0001166873769759751\n",
      ". \n",
      "Weights : \n",
      "[ 0.05963404  1.05542395 -0.0640657 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 121.\n",
      "Error : 7.467992126462521e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.05963404  1.05628812 -0.06320153]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 122.\n",
      "Error : 1.2726988169879809e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.05999078  1.05628812 -0.06284478]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 123.\n",
      "Error : 8.145272428723078e-06\n",
      ". \n",
      "Weights : \n",
      "[ 0.06027618  1.05628812 -0.06255938]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 124.\n",
      "Error : 3.932864350492859e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.06027618  1.05691525 -0.06193225]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 125.\n",
      "Error : 0.003835603903849782\n",
      ". \n",
      "Weights : \n",
      "[ 0.06027618  1.05691525 -0.05573903]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 126.\n",
      "Error : 0.0031068391621183232\n",
      ". \n",
      "Weights : \n",
      "[ 0.06027618  1.05691525 -0.05016512]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 127.\n",
      "Error : 0.0025165397213158416\n",
      ". \n",
      "Weights : \n",
      "[ 0.06027618  1.05691525 -0.04514861]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 128.\n",
      "Error : 0.00022884343694350065\n",
      ". \n",
      "Weights : \n",
      "[ 0.05876343  1.05691525 -0.04666137]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 129.\n",
      "Error : 0.004763388517155966\n",
      ". \n",
      "Weights : \n",
      "[ 0.0518617   1.05001352 -0.0535631 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 130.\n",
      "Error : 2.8947739496114604e-06\n",
      ". \n",
      "Weights : \n",
      "[ 0.05203184  1.05001352 -0.05339296]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 131.\n",
      "Error : 0.0028508081289357772\n",
      ". \n",
      "Weights : \n",
      "[ 0.05203184  1.05001352 -0.04805366]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 132.\n",
      "Error : 1.5825861497632233e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.05163402  1.05001352 -0.04845148]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 133.\n",
      "Error : 2.4399588622671114e-06\n",
      ". \n",
      "Weights : \n",
      "[ 0.05163402  1.04985731 -0.04860768]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 134.\n",
      "Error : 1.5615736718513953e-06\n",
      ". \n",
      "Weights : \n",
      "[ 0.05163402  1.04973235 -0.04873265]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 135.\n",
      "Error : 9.994071499850706e-07\n",
      ". \n",
      "Weights : \n",
      "[ 0.05163402  1.04963238 -0.04883262]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 136.\n",
      "Error : 7.847850573476079e-06\n",
      ". \n",
      "Weights : \n",
      "[ 0.05135388  1.04963238 -0.04911276]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 137.\n",
      "Error : 5.022624367024703e-06\n",
      ". \n",
      "Weights : \n",
      "[ 0.05112977  1.04963238 -0.04933687]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 138.\n",
      "Error : 8.732648404607747e-08\n",
      ". \n",
      "Weights : \n",
      "[ 0.05112977  1.04960283 -0.04936642]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 139.\n",
      "Error : 5.588894978940559e-08\n",
      ". \n",
      "Weights : \n",
      "[ 0.05112977  1.04957919 -0.04939006]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 140.\n",
      "Error : 3.5768927865253176e-08\n",
      ". \n",
      "Weights : \n",
      "[ 0.05112977  1.04956028 -0.04940897]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 141.\n",
      "Error : 0.0026297479902166465\n",
      ". \n",
      "Weights : \n",
      "[ 0.04600166  1.04443217 -0.05453708]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 142.\n",
      "Error : 7.28534167186267e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.0468552   1.04443217 -0.05368354]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 143.\n",
      "Error : 4.662618669992109e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.04753804  1.04443217 -0.05300071]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 144.\n",
      "Error : 7.34198172914646e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.04753804  1.04528902 -0.05214385]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 145.\n",
      "Error : 4.698868306653674e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.04753804  1.04597451 -0.05145837]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 146.\n",
      "Error : 1.53690113402653e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.04793007  1.04597451 -0.05106634]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 147.\n",
      "Error : 2.592673311867409e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.04793007  1.04648369 -0.05055715]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 148.\n",
      "Error : 6.9015674445509875e-06\n",
      ". \n",
      "Weights : \n",
      "[ 0.04819278  1.04648369 -0.05029444]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 149.\n",
      "Error : 0.0025295311501229377\n",
      ". \n",
      "Weights : \n",
      "[ 0.04819278  1.04648369 -0.045265  ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 150.\n",
      "Error : 0.002441493025149349\n",
      ". \n",
      "Weights : \n",
      "[ 0.04325163  1.04154254 -0.05020615]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 151.\n",
      "Error : 4.8365287413534536e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.04394708  1.04154254 -0.0495107 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 152.\n",
      "Error : 0.001294483382156057\n",
      ". \n",
      "Weights : \n",
      "[ 0.04034919  1.03794465 -0.05310859]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 153.\n",
      "Error : 0.00022994504347289988\n",
      ". \n",
      "Weights : \n",
      "[ 0.04034919  1.03946104 -0.05159219]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 154.\n",
      "Error : 0.00012640515104773422\n",
      ". \n",
      "Weights : \n",
      "[ 0.04147349  1.03946104 -0.05046789]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 155.\n",
      "Error : 0.000121150761883545\n",
      ". \n",
      "Weights : \n",
      "[ 0.04147349  1.04056173 -0.04936721]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 156.\n",
      "Error : 0.001067198852204662\n",
      ". \n",
      "Weights : \n",
      "[ 0.03820669  1.03729493 -0.05263401]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 157.\n",
      "Error : 0.0027703389752934157\n",
      ". \n",
      "Weights : \n",
      "[ 0.03820669  1.03729493 -0.04737061]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 158.\n",
      "Error : 0.00010151935765744374\n",
      ". \n",
      "Weights : \n",
      "[ 0.03820669  1.0383025  -0.04636304]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 159.\n",
      "Error : 0.002149531530405485\n",
      ". \n",
      "Weights : \n",
      "[ 0.03820669  1.0383025  -0.04172674]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 160.\n",
      "Error : 1.172542740033336e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.03820669  1.03864492 -0.04138431]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 161.\n",
      "Error : 7.504273536213473e-06\n",
      ". \n",
      "Weights : \n",
      "[ 0.03820669  1.03891886 -0.04111037]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 162.\n",
      "Error : 0.0016900627766380826\n",
      ". \n",
      "Weights : \n",
      "[ 0.03820669  1.03891886 -0.03699934]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 163.\n",
      "Error : 3.6845684677482574e-06\n",
      ". \n",
      "Weights : \n",
      "[ 0.03820669  1.03872691 -0.03719129]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 164.\n",
      "Error : 2.3581238193586118e-06\n",
      ". \n",
      "Weights : \n",
      "[ 0.03820669  1.03857334 -0.03734485]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 165.\n",
      "Error : 7.427669248170679e-07\n",
      ". \n",
      "Weights : \n",
      "[ 0.03812051  1.03857334 -0.03743103]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 166.\n",
      "Error : 4.7537083188292533e-07\n",
      ". \n",
      "Weights : \n",
      "[ 0.03805156  1.03857334 -0.03749998]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 167.\n",
      "Error : 3.042373324050722e-07\n",
      ". \n",
      "Weights : \n",
      "[ 0.0379964   1.03857334 -0.03755514]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 168.\n",
      "Error : 1.0367433060580587e-06\n",
      ". \n",
      "Weights : \n",
      "[ 0.0379964   1.03847152 -0.03765696]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 169.\n",
      "Error : 6.635157158769405e-07\n",
      ". \n",
      "Weights : \n",
      "[ 0.0379964   1.03839007 -0.03773842]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 170.\n",
      "Error : 0.001493671939454422\n",
      ". \n",
      "Weights : \n",
      "[ 0.0341316   1.03452526 -0.04160322]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 171.\n",
      "Error : 0.0007318992503326776\n",
      ". \n",
      "Weights : \n",
      "[ 0.03142623  1.0318199  -0.04430858]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 172.\n",
      "Error : 0.00015596727697079628\n",
      ". \n",
      "Weights : \n",
      "[ 0.03142623  1.03306877 -0.04305972]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 173.\n",
      "Error : 9.98190572613074e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.03142623  1.03406786 -0.04206062]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 174.\n",
      "Error : 0.00011309024299702425\n",
      ". \n",
      "Weights : \n",
      "[ 0.03248967  1.03406786 -0.04099718]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 175.\n",
      "Error : 7.237775551809557e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.03334042  1.03406786 -0.04014643]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 176.\n",
      "Error : 4.6321763531581086e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.03402102  1.03406786 -0.03946583]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 177.\n",
      "Error : 2.9645928660211835e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.0345655   1.03406786 -0.03892135]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 178.\n",
      "Error : 0.0008828039048759816\n",
      ". \n",
      "Weights : \n",
      "[ 0.0315943   1.03109666 -0.04189255]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 179.\n",
      "Error : 0.00010605393720641723\n",
      ". \n",
      "Weights : \n",
      "[ 0.03262413  1.03109666 -0.04086273]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 180.\n",
      "Error : 0.0005224909602187293\n",
      ". \n",
      "Weights : \n",
      "[ 0.03033832  1.02881085 -0.04314853]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 181.\n",
      "Error : 0.00020556900285900967\n",
      ". \n",
      "Weights : \n",
      "[ 0.03033832  1.03024462 -0.04171476]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 182.\n",
      "Error : 0.00013156416182976772\n",
      ". \n",
      "Weights : \n",
      "[ 0.03033832  1.03139164 -0.04056775]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 183.\n",
      "Error : 8.420106357104929e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.03033832  1.03230925 -0.03965014]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 184.\n",
      "Error : 8.67099591125262e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.0312695   1.03230925 -0.03871896]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 185.\n",
      "Error : 0.0006180093179702528\n",
      ". \n",
      "Weights : \n",
      "[ 0.02878352  1.02982327 -0.04120494]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 186.\n",
      "Error : 0.0001295423622721686\n",
      ". \n",
      "Weights : \n",
      "[ 0.02878352  1.03096144 -0.04006677]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 187.\n",
      "Error : 0.00012731165063504057\n",
      ". \n",
      "Weights : \n",
      "[ 0.02991185  1.03096144 -0.03893844]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 188.\n",
      "Error : 0.0015162024887836708\n",
      ". \n",
      "Weights : \n",
      "[ 0.02991185  1.03096144 -0.0350446 ]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 189.\n",
      "Error : 0.0006671208439218362\n",
      ". \n",
      "Weights : \n",
      "[ 0.02732898  1.02837857 -0.03762747]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 190.\n",
      "Error : 0.0003268892135216925\n",
      ". \n",
      "Weights : \n",
      "[ 0.02552097  1.02657056 -0.03943548]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 191.\n",
      "Error : 0.00016550609451017307\n",
      ". \n",
      "Weights : \n",
      "[ 0.02552097  1.02785705 -0.03814898]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 192.\n",
      "Error : 0.0002319235955049733\n",
      ". \n",
      "Weights : \n",
      "[ 0.02399807  1.02633415 -0.03967189]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 193.\n",
      "Error : 0.0002456686527868862\n",
      ". \n",
      "Weights : \n",
      "[ 0.02556545  1.02633415 -0.03810451]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 194.\n",
      "Error : 0.00019030452623700875\n",
      ". \n",
      "Weights : \n",
      "[ 0.02418594  1.02495464 -0.03948402]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 195.\n",
      "Error : 0.00021110280788917715\n",
      ". \n",
      "Weights : \n",
      "[ 0.02418594  1.02640758 -0.03803108]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 196.\n",
      "Error : 0.0001351057970490713\n",
      ". \n",
      "Weights : \n",
      "[ 0.02418594  1.02756993 -0.03686873]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 197.\n",
      "Error : 8.646771011140895e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.02418594  1.02849981 -0.03593885]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 198.\n",
      "Error : 0.00013813081210519495\n",
      ". \n",
      "Weights : \n",
      "[ 0.02536123  1.02849981 -0.03476356]\n",
      "\n",
      "\n",
      "**********\n",
      "Iteration : 199.\n",
      "Error : 8.840371974732482e-05\n",
      ". \n",
      "Weights : \n",
      "[ 0.02630146  1.02849981 -0.03382332]\n",
      "\n",
      "\n",
      "Test:\n",
      "Input : (1, 1, 1)\n",
      " Predict : 1.0209779459893777\n",
      " Goal predict : 1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "weights = np.array([.5, .48, -.7])\n",
    "alpha = 0.1\n",
    "\n",
    "street = np.array( [\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [0, 0, 1],\n",
    "    [1, 1, 1],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1] ] )\n",
    "\n",
    "walk_and_stop = np.array( [0, 1, 0, 1, 1, 0] )\n",
    "\n",
    "for i in range(200):\n",
    "    #Init dataset for learning net\n",
    "    tmp = random.randint(0,5)\n",
    "    input_s = street[tmp]\n",
    "    goal = walk_and_stop[tmp]\n",
    "    \n",
    "    #Learning\n",
    "    \n",
    "    predict = input_s.dot(weights)\n",
    "    error = (predict - goal) ** 2\n",
    "    weights -= (predict - goal)*input_s*alpha\n",
    "    \n",
    "    print(\"**********\\nIteration : {0}.\\nError : {1}\\n. \\nWeights : \\n{2}\\n\\n\".format(i, error, weights))\n",
    "print(\"Test:\\nInput : (1, 1, 1)\\n Predict : {0}\\n Goal predict : {1}\".format(\n",
    "np.array([1, 1, 1]).dot(weights), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : 0.02317222265722177\n",
      "\n",
      "Error : 0.37697998088916795\n",
      "\n",
      "Error : 0.5585446349508787\n",
      "\n",
      "Error : 0.6342311598444467\n",
      "\n",
      "Error : 6.583974603752558e-05\n",
      "\n",
      "Error : 0.18340014797885185\n",
      "\n",
      "Error : 0.31497070417381795\n",
      "\n",
      "Error : 0.35838407676317513\n",
      "\n",
      "Error : 1.2854807174765666e-14\n",
      "\n",
      "Error : 0.032716692228431515\n",
      "\n",
      "Error : 0.07944050755997109\n",
      "\n",
      "Error : 0.0830183113303298\n",
      "\n",
      "Error : 2.438025114683471e-24\n",
      "\n",
      "Error : 0.0016192127634249867\n",
      "\n",
      "Error : 0.006448232304230192\n",
      "\n",
      "Error : 0.006467054957103705\n",
      "\n",
      "Error : 0.0\n",
      "\n",
      "Error : 6.299054636709449e-05\n",
      "\n",
      "Error : 0.0003292669000750734\n",
      "\n",
      "Error : 0.0003292669000750734\n",
      "\n",
      "Error : 0.0\n",
      "\n",
      "Error : 2.8586146897158e-06\n",
      "\n",
      "Error : 1.5055622665134859e-05\n",
      "\n",
      "Error : 1.5055622665134859e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def relu(x):\n",
    "    return (x > 0)*x\n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output > 0\n",
    "np.random.seed(1)\n",
    "\n",
    "alpha = 0.2\n",
    "hidden_size = 4\n",
    "\n",
    "street = np.array([\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [0, 0, 1],\n",
    "    [1, 1, 1] ])\n",
    "walk_and_stop = np.array([1, 1, 0, 0])\n",
    "\n",
    "weights_0_1 = 2*np.random.random((3, hidden_size)) - 1\n",
    "weights_1_2 = 2*np.random.random((hidden_size, 1)) - 1\n",
    "\n",
    "#layer_0 = street[0]\n",
    "#layer_1 = relu(np.dot(layer_0, weights_0_1)) for one iteration\n",
    "#layer_2 = np.dot(layer_1, weights_1_2)\n",
    "\n",
    "for iteration in range(60):\n",
    "    layer_2_error = 0\n",
    "    for i in range(len(street)):\n",
    "        layer_0 = street[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        layer_2_error += np.sum((layer_2-walk_and_stop[i:i+1]) ** 2)\n",
    "        \n",
    "        layer_2_delta = (walk_and_stop[i:i+1]-layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "        if (iteration % 10 == 9):\n",
    "            print(\"Error : {0}\\n\".format(layer_2_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Dataset for recognition MNIST of third layer neural net\n",
    "from keras.datasets import mnist\n",
    "import sys, numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I:0 Error:0.664 Correct:0.634\n",
      " I:1 Error:0.435 Correct:0.808\n",
      " I:2 Error:0.356 Correct:0.87\n",
      " I:3 Error:0.305 Correct:0.9\n",
      " I:4 Error:0.268 Correct:0.918\n",
      " I:5 Error:0.241 Correct:0.932\n",
      " I:6 Error:0.218 Correct:0.94\n",
      " I:7 Error:0.200 Correct:0.953\n",
      " I:8 Error:0.185 Correct:0.962\n",
      " I:9 Error:0.172 Correct:0.965\n",
      " I:10 Error:0.161 Correct:0.971\n",
      " I:11 Error:0.151 Correct:0.975\n",
      " I:12 Error:0.142 Correct:0.979\n",
      " I:13 Error:0.134 Correct:0.985\n",
      " I:14 Error:0.127 Correct:0.989\n",
      " I:15 Error:0.121 Correct:0.992\n",
      " I:16 Error:0.115 Correct:0.993\n",
      " I:17 Error:0.110 Correct:0.993\n",
      " I:18 Error:0.105 Correct:0.996\n",
      " I:19 Error:0.100 Correct:0.996\n",
      " I:20 Error:0.096 Correct:0.997\n",
      " I:21 Error:0.092 Correct:0.998\n",
      " I:22 Error:0.088 Correct:0.998\n",
      " I:23 Error:0.085 Correct:1.0\n",
      " I:24 Error:0.081 Correct:1.0\n",
      " I:25 Error:0.078 Correct:1.0\n",
      " I:26 Error:0.075 Correct:1.0\n",
      " I:27 Error:0.072 Correct:1.0\n",
      " I:28 Error:0.070 Correct:1.0\n",
      " I:29 Error:0.067 Correct:1.0\n"
     ]
    }
   ],
   "source": [
    "images, labels = (x_train[0:1000].reshape(1000,28*28)/255, y_train[0:1000])\n",
    "one_hot_labels = np.zeros((len(y_test),10))\n",
    "for i, l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i, l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "relu = lambda x: (x >= 0)*x\n",
    "relu_derive = lambda x: x > 0\n",
    "\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 30, 100, 784, 10)\n",
    "weights_0_l = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_l_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_l))\n",
    "        layer_2 = np.dot(layer_1, weights_l_2)\n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = (layer_2_delta.dot(weights_l_2.T) * relu_derive(layer_1))\n",
    "        \n",
    "        weights_l_2 += alpha * (layer_1.T).dot(layer_2_delta)\n",
    "        weights_0_l += alpha * (layer_0.T).dot(layer_1_delta)\n",
    "    print(\"\\r\"+ \\\n",
    "\" I:\"+str(j)+ \\\n",
    "\" Error:\" + str(error/float(len(images)))[0:5] +\\\n",
    "\" Correct:\" + str(correct_cnt/float(len(images))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test-Err:0.293 Test-Acc:0.8877\n"
     ]
    }
   ],
   "source": [
    "if (j % 10 == 0 or j == iterations - 1):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i in range(len(test_images)):\n",
    "        layer_0 = test_images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_l))\n",
    "        layer_2 = np.dot(layer_1, weights_l_2)\n",
    "        \n",
    "        error += np.sum((test_labels[i]-layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "        \n",
    "print(\" Test-Err:\" + str(error/float(len(test_images)))[0:5] +\\\n",
    "\" Test-Acc:\" + str(correct_cnt/float(len(test_images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "#dropout in neural network\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28)/255, y_train[0:1000])\n",
    "one_hot_labels = np.zeros((len(y_test),10))\n",
    "for i, l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i, l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "relu = lambda x: (x >= 0)*x\n",
    "relu_derive = lambda x: x > 0\n",
    "\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 100, 100, 784, 10)\n",
    "weights_0_l = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_l_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_l))\n",
    "        #drop init\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2        \n",
    "        layer_2 = np.dot(layer_1, weights_l_2)\n",
    "        \n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
    "        \n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = (layer_2_delta.dot(weights_l_2.T) * relu_derive(layer_1))\n",
    "        layer_1_delta *= dropout_mask\n",
    "        \n",
    "        weights_l_2 += alpha * (layer_1.T).dot(layer_2_delta)\n",
    "        weights_0_l += alpha * (layer_0.T).dot(layer_1_delta)\n",
    "    #print(\"\\r\"+\" I:\"+str(j)+\" Error:\" + str(error/float(len(images)))[0:5] \" Correct:\" + str(correct_cnt/float(len(images))))\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test-Err:0.283 Test-Acc:0.8804\n"
     ]
    }
   ],
   "source": [
    "if (j % 10 == 0 or j == iterations - 1):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i in range(len(test_images)):\n",
    "        layer_0 = test_images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_l))\n",
    "        layer_2 = np.dot(layer_1, weights_l_2)\n",
    "        \n",
    "        error += np.sum((test_labels[i]-layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "        \n",
    "print(\" Test-Err:\" + str(error/float(len(test_images)))[0:5] +\\\n",
    "\" Test-Acc:\" + str(correct_cnt/float(len(test_images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test-Err:0.824 Test-Acc:0.3752\n",
      " Test-Err:0.543 Test-Acc:0.7264\n",
      " Test-Err:0.464 Test-Acc:0.7757\n",
      " Test-Err:0.418 Test-Acc:0.8061\n",
      " Test-Err:0.389 Test-Acc:0.8197\n",
      " Test-Err:0.366 Test-Acc:0.8317\n",
      " Test-Err:0.351 Test-Acc:0.8445\n",
      " Test-Err:0.340 Test-Acc:0.8513\n",
      " Test-Err:0.331 Test-Acc:0.8534\n",
      " Test-Err:0.323 Test-Acc:0.8585\n",
      " Test-Err:0.316 Test-Acc:0.8625\n",
      " Test-Err:0.312 Test-Acc:0.8641\n",
      " Test-Err:0.306 Test-Acc:0.8642\n",
      " Test-Err:0.302 Test-Acc:0.8667\n",
      " Test-Err:0.301 Test-Acc:0.8703\n",
      " Test-Err:0.297 Test-Acc:0.8691\n",
      " Test-Err:0.296 Test-Acc:0.8726\n",
      " Test-Err:0.295 Test-Acc:0.8733\n",
      " Test-Err:0.292 Test-Acc:0.8733\n",
      " Test-Err:0.288 Test-Acc:0.8746\n",
      " Test-Err:0.290 Test-Acc:0.8748\n",
      " Test-Err:0.287 Test-Acc:0.8767\n",
      " Test-Err:0.287 Test-Acc:0.876\n",
      " Test-Err:0.287 Test-Acc:0.877\n",
      " Test-Err:0.286 Test-Acc:0.8761\n",
      " Test-Err:0.285 Test-Acc:0.8773\n",
      " Test-Err:0.285 Test-Acc:0.8757\n",
      " Test-Err:0.283 Test-Acc:0.8788\n",
      " Test-Err:0.281 Test-Acc:0.8778\n",
      " Test-Err:0.282 Test-Acc:0.8758\n",
      " Test-Err:0.282 Test-Acc:0.8776\n"
     ]
    }
   ],
   "source": [
    "#Batches for Neural net.   \n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28)/255, y_train[0:1000])\n",
    "one_hot_labels = np.zeros((len(y_test),10))\n",
    "for i, l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i, l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "relu = lambda x: (x >= 0)*x\n",
    "relu_derive = lambda x: x > 0\n",
    "\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.001, 300, 100, 784, 10)\n",
    "weights_0_l = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_l_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "batch_size = 100\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(int(len(images)/batch_size)):\n",
    "        batch_start, batch_end = ((i * batch_size), ((i+1)*batch_size))\n",
    "        layer_0 = images[batch_start:batch_end]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_l))\n",
    "        #drop init\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2        \n",
    "        layer_2 = np.dot(layer_1, weights_l_2)\n",
    "        \n",
    "        error += np.sum((labels[batch_start:batch_end] - layer_2) ** 2)\n",
    "        for k in range(batch_size):\n",
    "            correct_cnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[k+batch_start:batch_start+k+1]))\n",
    "        \n",
    "            layer_2_delta = (labels[batch_start:batch_end] - layer_2) / batch_size\n",
    "            layer_1_delta = (layer_2_delta.dot(weights_l_2.T) * relu_derive(layer_1))\n",
    "            layer_1_delta *= dropout_mask\n",
    "        \n",
    "            weights_l_2 += alpha * (layer_1.T).dot(layer_2_delta)\n",
    "            weights_0_l += alpha * (layer_0.T).dot(layer_1_delta)\n",
    "    if (j % 10 == 0 or j == iterations - 1):\n",
    "        error, correct_cnt = (0.0, 0)\n",
    "\n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0, weights_0_l))\n",
    "            layer_2 = np.dot(layer_1, weights_l_2)\n",
    "\n",
    "            error += np.sum((test_labels[i]-layer_2) ** 2)\n",
    "            correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "\n",
    "        print(\" Test-Err:\" + str(error/float(len(test_images)))[0:5] +\\\n",
    "    \" Test-Acc:\" + str(correct_cnt/float(len(test_images))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test-Err: 0 - 1.803 Test-Acc:0.098\n",
      " Test-Err: 1 - 0.372 Test-Acc:0.7352\n",
      " Test-Err: 2 - 0.388 Test-Acc:0.7583\n",
      " Test-Err: 3 - 0.411 Test-Acc:0.7082\n",
      " Test-Err: 4 - 0.412 Test-Acc:0.7133\n",
      " Test-Err: 5 - 0.417 Test-Acc:0.6989\n",
      " Test-Err: 6 - 0.412 Test-Acc:0.695\n",
      " Test-Err: 7 - 0.409 Test-Acc:0.7048\n"
     ]
    }
   ],
   "source": [
    "images, labels = (x_train[0:1000].reshape(1000,28*28)/255, y_train[0:1000])\n",
    "one_hot_labels = np.zeros((len(y_test),10))\n",
    "for i, l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i, l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "#Function for activation neuron in hidden and output layers\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derive(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "    \n",
    "def tanh_derive(x):\n",
    "    return 1 - (np.tanh(x)) ** 2\n",
    "\n",
    "def softmax(x):\n",
    "    temp = np.exp(x)\n",
    "    return temp/(np.sum(temp, axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (2, 500, 100, 784, 10)\n",
    "batch_size = 100\n",
    "\n",
    "#Weights (input, hidden), (hidden, output)\n",
    "weights_0_l = 0.02*np.random.random((pixels_per_image,hidden_size)) - 0.01\n",
    "weights_l_2 = 0.02*np.random.random((hidden_size,num_labels)) - 0.01\n",
    "\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(int(len(images)/batch_size)):\n",
    "        batch_start, batch_end = ((i * batch_size), ((i+1)*batch_size))\n",
    "        layer_0 = images[batch_start:batch_end]\n",
    "        layer_1 = tanh(np.dot(layer_0, weights_0_l))\n",
    "        #drop init\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2        \n",
    "        layer_2 = softmax(np.dot(layer_1, weights_l_2))\n",
    "        \n",
    "        error += np.sum((labels[batch_start:batch_end] - layer_2) ** 2)\n",
    "        for k in range(batch_size):\n",
    "            correct_cnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[k+batch_start:batch_start+k+1]))\n",
    "        \n",
    "            layer_2_delta = (labels[batch_start:batch_end] - layer_2) / (batch_size*layer_2.shape[0])\n",
    "            \n",
    "            layer_1_delta = (layer_2_delta.dot(weights_l_2.T) * tanh_derive(layer_1))\n",
    "            layer_1_delta *= dropout_mask\n",
    "        \n",
    "            weights_l_2 += alpha * (layer_1.T).dot(layer_2_delta)\n",
    "            weights_0_l += alpha * (layer_0.T).dot(layer_1_delta)\n",
    "            \n",
    "    if (j % 10 == 0 or j == iterations - 1):\n",
    "        error, correct_cnt = (0.0, 0)\n",
    "\n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = tanh(np.dot(layer_0, weights_0_l))\n",
    "            layer_2 = softmax(np.dot(layer_1, weights_l_2))\n",
    "\n",
    "            error += np.sum((test_labels[i]-layer_2) ** 2)\n",
    "            correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "\n",
    "        print(\" Test-Err: \"+str(j // 10) + \" - \"+str(error/float(len(test_images)))[0:5] +\\\n",
    "    \" Test-Acc:\" + str(correct_cnt/float(len(test_images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     9,
     15,
     18,
     21,
     24,
     27
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcoder/anaconda3/envs/ml/lib/python3.5/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n",
      "\n",
      "I:0 Test-Acc:0.0Train-Acc:0.0\n"
     ]
    }
   ],
   "source": [
    "#CNN -   \n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28)/255, y_train[0:1000])\n",
    "one_hot_labels = np.zeros((len(y_test),10))\n",
    "for i, l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i, l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "#Function for activation neuron in hidden and output layers\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derive(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "    \n",
    "def tanh_derive(x):\n",
    "    return 1 - (np.tanh(x)) ** 2\n",
    "\n",
    "def softmax(x):\n",
    "    temp = np.exp(x)\n",
    "    return temp/(np.sum(temp, axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "alpha, iterations = 2, 300\n",
    "pixels_per_image, num_labels = (784, 10)\n",
    "batch_size = 128\n",
    "\n",
    "input_rows = 28\n",
    "input_cols = 28\n",
    "\n",
    "kernel_rows = 3\n",
    "kernel_cols = 3\n",
    "num_kernels = 16\n",
    "\n",
    "hidden_size = (input_rows - kernel_rows)*(input_cols - kernel_cols)*num_kernels\n",
    "\n",
    "kernels = 0.02*np.random.random((kernel_rows*kernel_cols, num_kernels)) - 0.01\n",
    "weights_l_2 = 0.02*np.random.random((hidden_size,num_labels)) - 0.01\n",
    "\n",
    "def get_image_section(layer, row_from, row_to, col_from, col_to):\n",
    "    section = layer[:, row_from:row_to, col_from:col_to]\n",
    "    return section.reshape(-1, 1, row_to-row_from, col_to-col_from)\n",
    "\n",
    "for j in range(iterations):\n",
    "    correct_cnt = 0\n",
    "    for i in range(int(len(images)/batch_size)):\n",
    "        batch_start, batch_end = i*batch_size, (i+1)*batch_size\n",
    "        layer_0 = images[batch_start:batch_end]\n",
    "        layer_0 = layer_0.reshape(layer_0.shape[0],28,28)\n",
    "        layer_0.shape\n",
    "        \n",
    "        sects = []\n",
    "        for row_start in range(layer_0.shape[1]-kernel_rows):\n",
    "            for col_start in range(layer_0.shape[2]-kernel_cols):\n",
    "                sect = get_image_section(layer_0,\n",
    "                                        row_start,\n",
    "                                        row_start+kernel_rows,\n",
    "                                        col_start,\n",
    "                                        col_start+kernel_cols)\n",
    "                sects.append(sect)\n",
    "        expanded_input = np.concatenate(sects, axis=1)\n",
    "        es = expanded_input.shape\n",
    "        \n",
    "        flattened_input = expanded_input.reshape(es[0]*es[1], -1)\n",
    "        kernel_output = flattened_input.dot(kernels)\n",
    "        \n",
    "        layer_1 = tanh(kernel_output.reshape(es[0], -1))\n",
    "        \n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        \n",
    "        layer_1 *= dropout_mask*2\n",
    "        layer_2 = softmax(np.dot(layer_1, weights_l_2))\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            label_set = labels[batch_start+k:batch_start+k+1]\n",
    "            _inc = int(np.argmax(layer_2[k:k+1]==np.argmax(label_set)))\n",
    "            correct_cnt += _inc\n",
    "            layer_2_delta = (labels[batch_start:batch_end]-layer_2) / (batch_size*layer_2.shape[0])\n",
    "            layer_1_delta = layer_2_delta.dot(weights_l_2.T) * tanh_derive(layer_1)\n",
    "            layer_1_delta *= dropout_mask\n",
    "            \n",
    "            weights_l_2 += alpha * (layer_1.T).dot(layer_2_delta)\n",
    "            l1d_reshape = layer_1_delta.reshape(kernel_output.shape)\n",
    "            k_update= flattened_input.T.dot(l1d_reshape)\n",
    "            kernels -= alpha*k_update\n",
    "            \n",
    "    test_correct_cnt = 0          \n",
    "    for i in range(len(test_images)):\n",
    "        layer_0 = test_images\n",
    "        layer_0 = layer_0.reshape(layer_0.shape[0],28,28)\n",
    "        layer_0.shape\n",
    "        sects = []\n",
    "        for row_start in range(layer_0.shape[1]-kernel_rows):\n",
    "            for col_start in range(layer_0.shape[2]-kernel_cols):\n",
    "                sect = get_image_section(layer_0,row_start,row_start+kernel_rows, col_start, col_start+kernel_cols)\n",
    "                sects.append(sect)\n",
    "            expanded_input = np.concatenate(sects, axis=1)\n",
    "            es = expanded_input.shape\n",
    "\n",
    "            flattened_input = expanded_input.reshape(es[0]*es[1], -1)\n",
    "            kernel_output = flattened_input.dot(kernels)\n",
    "\n",
    "            layer_1 = tanh(kernel_output.reshape(es[0], -1))\n",
    "\n",
    "            dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "\n",
    "            layer_1 *= dropout_mask*2\n",
    "            layer_2 = softmax(np.dot(layer_1.T, weights_l_2))\n",
    "\n",
    "            test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "            if(j % 1 == 0):\n",
    "                print(\"\\n\"+\"I:\" + str(j) +\" Test-Acc:\"+str(test_correct_cnt/float(len(test_images)))+ \"Train-Acc:\" + str(correct_cnt/float(len(images))))\n",
    "        \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download OK\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "f = open('reviews.txt')\n",
    "raw_rewiews = f.readlines()\n",
    "f.close()\n",
    "\n",
    "f = open('labels.txt')\n",
    "raw_labels = f.readlines()\n",
    "f.close()\n",
    "\n",
    "tokens = list(map(lambda x: set(x.split()),raw_rewiews))\n",
    "\n",
    "vocab = set()\n",
    "for sent in tokens:\n",
    "    for word in sent:\n",
    "        if len(word) > 0:\n",
    "            vocab.add(word)\n",
    "vocab = list(vocab)\n",
    "\n",
    "word2index = {}\n",
    "for i, word in enumerate(vocab):\n",
    "    word2index[word] = i\n",
    "    \n",
    "input_dataset = []\n",
    "for sent in tokens:\n",
    "    sent_indeces = []\n",
    "    for word in sent:\n",
    "        try:\n",
    "            sent_indeces.append(word2index[word])\n",
    "        except:\n",
    "            \"\"\n",
    "    input_dataset.append(list(set(sent_indeces)))\n",
    "target_dataset = []\n",
    "for label in raw_labels:\n",
    "    if label == 'positive\\n':\n",
    "        target_dataset.append(1)\n",
    "    else:\n",
    "        target_dataset.append(0)\n",
    "print(\"Dataset download OK\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.552\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "alpha, iterations = 0.1, 2\n",
    "hidden_size = 100\n",
    "\n",
    "weights_0_1 = 0.2 * np.random.random((len(vocab), hidden_size)) -0.1\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size, 1)) - 0.1\n",
    "\n",
    "correct, total = 0,0 \n",
    "for iter in range(iterations):\n",
    "    for i in range(len(input_dataset)-1000):\n",
    "        x, y = (input_dataset[i], target_dataset[i])\n",
    "        layer_1 = sigmoid(np.sum(weights_0_1[x],axis=0))\n",
    "        layer_2 = sigmoid(np.dot(layer_1, weights_1_2))\n",
    "        \n",
    "        layer_2_delta = layer_2 - y\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)\n",
    "        \n",
    "        weights_0_1[x] -= layer_1_delta *alpha\n",
    "        weights_1_2 -= np.outer(layer_1, layer_2_delta) * alpha\n",
    "                  \n",
    "                  \n",
    "correctjtotal = (0,0)\n",
    "                  \n",
    "for i in range(len(input_dataset)-1000,len(input_dataset)) :\n",
    "    x = input_dataset[i]\n",
    "     = target_dataset[i]\n",
    "    layer_1 = sigmoid(np.sum(weights_0_1[x],axis=0))\n",
    "    layer_2 = sigmoid(np.dot(layer_1,weights_1_2))\n",
    "    if(np.abs(layer_2 - y) < 0.5):\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(\"Test Accuracy:\" + str(correct / float(total)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello    \\nworld'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delete_white_space(string):\n",
    "    begin, end = 0,0\n",
    "    check_b, check_e = False, False\n",
    "    for i in range(len(string)):\n",
    "        if string[i] not in [' ', '\\n', '\\r'] and not check_b:\n",
    "            begin = i\n",
    "            check_b = True\n",
    "        if string[len(string)-1-i] not in [' ', '\\n', '\\r'] and not check_e:\n",
    "            end = len(string)-1-i\n",
    "            check_e = True\n",
    "        if check_e and check_b:\n",
    "            break\n",
    "    return string[begin:end+1]\n",
    "delete_white_space(\"    Hello    \\nworld \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
